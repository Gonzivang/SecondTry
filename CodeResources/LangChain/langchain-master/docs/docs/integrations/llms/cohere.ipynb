{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9597802c",
   "metadata": {},
   "source": [
    "# Cohere\n",
    "\n",
    ">[Cohere](https://cohere.ai/about) is a Canadian startup that provides natural language processing models that help companies improve human-machine interactions.\n",
    "\n",
    "Head to the [API reference](https://api.python.langchain.com/en/latest/llms/langchain_community.llms.cohere.Cohere.html) for detailed documentation of all attributes and methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873eb81e-6049-4a68-b219-baa421d7cba8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup\n",
    "\n",
    "The integration lives in the `langchain-community` package. We also need to install the `cohere` package itself. We can install these with:\n",
    "\n",
    "```bash\n",
    "pip install -U langchain-community cohere\n",
    "```\n",
    "\n",
    "We'll also need to get a [Cohere API key](https://cohere.com/) and set the `COHERE_API_KEY` environment variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f5dc9d7-65e3-4b5b-9086-3327d016cfe0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"COHERE_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07a576d-e39d-4ca2-8f16-41df284d136c",
   "metadata": {},
   "source": [
    "It's also helpful (but not needed) to set up [LangSmith](https://smith.langchain.com/) for best-in-class observability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af022d3-d24a-49fa-b660-ec76f1bce9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4e02bf-5beb-48af-a2a2-52cbcd8ebed6",
   "metadata": {},
   "source": [
    "## Usage\n",
    "\n",
    "Cohere supports all [LLM](/docs/modules/model_io/llms/) functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fb585dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.llms import Cohere\n",
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be042d9f-c625-4316-b5e5-272b5ce8904f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Cohere(model=\"command\", max_tokens=256, temperature=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cbfc906-4278-4bc9-8756-1681bb647752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Who's there?\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = \"Knock knock\"\n",
    "model.invoke(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9a9ffcf-5a74-4875-ad3e-d66d3b871f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Who's there?\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await model.ainvoke(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab3550b5-4271-4333-a75c-e4bce58c0452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Who's there?"
     ]
    }
   ],
   "source": [
    "for chunk in model.stream(message):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "587c850d-76bd-4f74-bcf7-50cdacec538e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\" Who's there?\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.batch([message])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39198f7d-6fc8-4662-954a-37ad38c4bec4",
   "metadata": {},
   "source": [
    "You can also easily combine with a prompt template for easy structuring of user input. We can do this using [LCEL](/docs/expression_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cbe3136-eff2-4e6a-807c-81cbf2a488a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d08eb676-dc24-41ae-ba32-19a95e22d3bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Why did the teddy bear cross the road?\\nBecause he had bear crossings.\\n\\nWould you like to hear another joke? '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\": \"bears\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4797d719",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
